<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>VAN-Flow</title>

  <style>
    body{
      font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Helvetica Neue",Arial,sans-serif;
      line-height:1.6;margin:0;background:#fff;color:#111;
    }

    .hero{ text-align:center; margin:60px 0 40px; padding:0 16px; }
    .hero h1{ font-size:44px; margin:0 0 10px; letter-spacing:-0.4px; }
    .brand{ font-weight:800; color:#FF2D8E; }
    .buttons{ margin-top:18px; }
    .buttons a{
      display:inline-block; padding:10px 18px; margin:6px;
      border-radius:10px; border:1px solid #ddd;
      text-decoration:none; color:#111; font-weight:600; background:#fff;
    }
    .buttons a:hover{ background:#f3f3f3; }

    .section{ max-width:900px; margin:0 auto 70px; padding:0 20px; }
    .section h2{ margin-top:0; letter-spacing:-0.2px; }

    .figure{ text-align:center; margin:30px 0 10px; }
    .figure img{
      max-width:100%; height:auto; border-radius:12px; border:1px solid #eee;
    }

    .caption{
      text-align:center; font-size:14px; color:#666; margin-top:10px;
    }

    /* ===== Qualitative Videos ===== */
    .video-section{ max-width:1300px; margin:0 auto 70px; padding:0 20px; }
    .video-section h2{ text-align:center; margin:0 0 18px; letter-spacing:-0.2px; }

    /* 1fr 1fr [BIG GAP] 1fr 1fr */
    .video-title-row{
      display:grid;
      grid-template-columns: 1fr 1fr 120px 1fr 1fr;
      align-items:end;
      margin-bottom:10px;
      text-align:center;
      font-weight:800;
    }
    .video-title{ font-size:16px; letter-spacing:-0.1px; }

    .video-grid{
      display:grid;
      grid-template-columns: 1fr 1fr 120px 1fr 1fr;
      align-items:start;
    }
    .video-spacer{ width:100%; }

    .video-card{ text-align:center; }
    .video-card p{ margin:6px 0 8px; font-size:14px; font-weight:700; }
    .tag-proposed{ color:#FF2D8E; }
    .tag-baseline{ color:#444; }

    /* Ensure a stable frame + avoid ‚Äúblack‚Äù due to layout/first-frame delay */
    .video-frame{
      position:relative;
      width:100%;
      aspect-ratio: 16 / 9;
      border-radius:12px;
      border:1px solid #eee;
      background:#000;
      overflow:hidden;
    }
    .video-frame video{
      position:absolute; inset:0;
      width:100%; height:100%;
      object-fit:cover;
      border:0;
      background:#000;
    }

    /* Small ‚Äúopen‚Äù link (helps when codec/autoplay fails) */
    .open-link{
      display:inline-block;
      margin-top:8px;
      font-size:12px;
      color:#777;
      text-decoration:none;
      border-bottom:1px solid transparent;
    }
    .open-link:hover{ border-bottom-color:#bbb; color:#555; }

    @media (max-width:1000px){
      .video-title-row{ grid-template-columns:1fr; gap:8px; }
      .video-grid{ grid-template-columns:1fr; gap:18px; }
      .video-spacer{ display:none; }
      .hero h1{ font-size:34px; }
    }
  </style>

  <!-- MathJax -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['\\[', '\\]']],
        processEscapes: true
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>

<body>

  <div class="hero">
    <h1>
      <span class="brand">VAN-Flow:</span>
      Variance-Averse $n$-Step Offline Reinforcement Learning <br>for Sparse Long-Horizon Environments
    </h1>
    <h2>ICML 2026</h2>
    <p><em>Anonymous Authors</em></p>

    <div class="buttons">
      <a href="paper.pdf">üìÑ Paper</a>
      <a href="https://github.com/your-repo">üíª Code</a>
    </div>
  </div>

  <!-- ===== Qualitative Videos ===== -->
  <div class="video-section">
    <h2>Qualitative Results</h2>

    <div class="video-title-row">
      <div></div>
      <div class="video-title">AntMaze-Play</div>
      <div></div>
      <div class="video-title">AntMaze-Explore</div>
      <div></div>
    </div>

    <div class="video-grid">
      <!-- Play / FQL-n -->
      <div class="video-card">
        <p class="tag-baseline">FQL-n</p>
        <div class="video-frame">
          <video autoplay loop muted playsinline preload="auto"
                 poster="assets/figures/qualitative/antmaze_play_fql_poster.png">
            <source src="assets/video/antmaze_play_fql.mp4" type="video/mp4">
          </video>
        </div>
        <a class="open-link" href="assets/video/antmaze_play_fql.mp4" target="_blank" rel="noopener">Open video</a>
      </div>

      <!-- Play / Ours -->
      <div class="video-card">
        <p class="tag-proposed">VAN-Flow (Ours)</p>
        <div class="video-frame">
          <video autoplay loop muted playsinline preload="auto"
                 poster="assets/figures/qualitative/antmaze_play_vanflow_poster.png">
            <source src="assets/video/antmaze_play_vanflow.mp4" type="video/mp4">
          </video>
        </div>
        <a class="open-link" href="assets/video/antmaze_play_vanflow.mp4" target="_blank" rel="noopener">Open video</a>
      </div>

      <!-- BIG GAP -->
      <div class="video-spacer"></div>

      <!-- Explore / FQL-n -->
      <div class="video-card">
        <p class="tag-baseline">FQL-n</p>
        <div class="video-frame">
          <video autoplay loop muted playsinline preload="auto"
                 poster="assets/figures/qualitative/antmaze_explore_fql_poster.png">
            <source src="assets/video/antmaze_explore_fql.mp4" type="video/mp4">
          </video>
        </div>
        <a class="open-link" href="assets/video/antmaze_explore_fql.mp4" target="_blank" rel="noopener">Open video</a>
      </div>

      <!-- Explore / Ours -->
      <div class="video-card">
        <p class="tag-proposed">VAN-Flow (Ours)</p>
        <div class="video-frame">
          <video autoplay loop muted playsinline preload="auto"
                 poster="assets/figures/qualitative/antmaze_explore_vanflow_poster.png">
            <source src="assets/video/antmaze_explore_vanflow.mp4" type="video/mp4">
          </video>
        </div>
        <a class="open-link" href="assets/video/antmaze_explore_vanflow.mp4" target="_blank" rel="noopener">Open video</a>
      </div>
    </div>

    <div class="caption">
      Qualitative comparison between FQL-n and the proposed variance-averse VAN-Flow.
    </div>
  </div>

  <!-- ===== Abstract ===== -->
  <div class="section">
    <h2>Abstract</h2>
    <p>
      Offline reinforcement learning (RL) in sparse, long-horizon environments is challenging because value estimation
      errors compound over long backup horizons. While $n$-step returns mitigate long-horizon bias, they amplify return
      variance, destabilizing offline learning. We propose <b style="color:#FF2D8E;">VAN-Flow</b>, a variance-averse
      offline RL framework that combines multi-step learning with categorical distributional value estimation and
      variance-aware target weighting.
    </p>
  </div>

  <!-- ===== Why Variance-Averse Training is Needed? ===== -->
  <div class="section">
    <h2>Why Variance-Averse Training is Needed?</h2>

    <div class="figure">
      <img src="assets/figures/why_variance_averse.png" alt="Why variance-averse training is needed">
    </div>
    <div class="caption">
      Offline RL performance on sparse-reward tasks under varying dataset return variance.
    </div>

    <p>
      Long-horizon decision-making under sparse rewards is notoriously challenging because informative feedback is
      delayed and rarely observed, making value estimation highly susceptible to error propagation. This issue becomes
      substantially more severe in offline RL, where learning is constrained to a fixed dataset with limited coverage.
      Prior work identifies that this difficulty is driven by the <em>curse of horizon</em>, where bootstrapping errors
      accumulate over long trajectories and degrade value accuracy. A common remedy is <em>value horizon reduction</em>,
      most notably $n$-step returns, which shorten the effective backup horizon.
    </p>

    <p>
      However, increasing the return horizon inevitably amplifies return variance, which can destabilize learning.
      In offline RL, this effect is further exacerbated because larger $n$ aggregates rewards collected under diverse
      behavior policies, yielding highly heterogeneous and high-variance return targets. As shown above, naively
      applying $n$-step returns (FQL-n) works well when dataset variance is low (<b>navigate</b>, <b>play</b>) but can
      become ineffective or even collapse under high-variance datasets (<b>explore</b>, <b>noisy</b>).
      In contrast, <span class="tag-proposed">variance-averse training</span> stabilizes learning by downweighting
      unreliable high-variance return targets, consistently recovering the benefits of long-horizon returns.
    </p>

    <p>
      These results suggest that the effectiveness of $n$-step returns in offline RL is fundamentally determined by
      how return variance is controlled. VAN-Flow explicitly models return uncertainty with a distributional critic,
      enabling variance-aware learning that preserves the bias-reduction benefits of $n$-step returns without suffering
      from variance amplification.
    </p>
  </div>

  <div class="footer" style="max-width:900px;margin:0 auto 40px auto;padding:0 20px;color:#777;font-size:13px;text-align:center;">
    ¬© Anonymous Authors ‚Ä¢ VAN-Flow Project Page
  </div>

</body>
</html>
